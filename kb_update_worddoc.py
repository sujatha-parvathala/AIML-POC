# -*- coding: utf-8 -*-
"""KB-update-wordDoc.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gLKsAmlpvGr_eQ_XUr3nNQFcNWpk75c6
"""

#required installations.
!pip install sentence-transformers faiss-cpu python-docx
!pip install -q gradio

#required imports.
from docx import Document
from sentence_transformers import SentenceTransformer
import faiss
import pickle

model = SentenceTransformer('all-mpnet-base-v2') #SentenceTransformer('sentence-transformers/all-MiniLM-L12-v2')
loaded_entries=[]
loaded_index=None
file_path = 'Problem.docx'

def LoadDocData(file_path):
  doc = Document(file_path)
  document_content = []
  for paragraph in doc.paragraphs:
      document_content.append(paragraph.text)

  # Loading the document entries by grouping Problem, Solution, and details
  entries = []
  current_entry = []
  for paragraph in document_content:
      if paragraph.strip():  # Checking if the paragraph is not empty or just whitespace
          if paragraph.strip().startswith("Problem:"):
              if current_entry: # If there's a previous entry, add it to entries
                  entries.append("\n".join(current_entry))
              current_entry = [paragraph.strip()] # Start a new entry
          else:
              current_entry.append(paragraph.strip()) # Add to the current entry

  # Add the last entry after the loop finishes
  if current_entry:
      entries.append("\n".join(current_entry))


  #creating embeddings for document entries
  # Load the model


  # Generating embeddings for each entry
  entry_embeddings = model.encode(entries)

  #Initializing a FAISS index with the correct embedding dimension is crucial because FAISS works by comparing vectors in that specific dimensional space.
  #If the dimension of the index doesn't match the dimension of our embeddings, FAISS won't be able to correctly process the vectors,
  #leading to errors or incorrect search results. the data won't align properly for the search to work.

  # Get the dimension of the embeddings
  embedding_dimension = entry_embeddings.shape[1]

  # Initialize a IndexFlatL2 FAISS index
  index = faiss.IndexFlatL2(embedding_dimension)

  # We have to add the generated embeddings to the FAISS index to create a searchable databse for our document entries
  #once the embeddings are added we can efficiently perform simlarity searches. (this allows for fast and scalable nearest
  # neighbors search which is required for finding duplicate entries or related information)

  # Add the embeddings to the index
  index.add(entry_embeddings)

  # Saving the FAISS index and the corresponding text entries to disk for later use.
  # Define file paths
  index_file = 'faiss_index.bin'
  entries_file = 'entries.pkl' # Using pickle to save list

  # Save the FAISS index
  faiss.write_index(index, index_file)
  print(f"FAISS index saved to {index_file}")

  # Save the entries list
  with open(entries_file, 'wb') as f:
      pickle.dump(entries, f)

def LoadEntries():
  index_file = 'faiss_index.bin'
  entries_file = 'entries.pkl'

  # Loading the FAISS index
  loaded_index = faiss.read_index(index_file)

  # Load the entries list
  with open(entries_file, 'rb') as f:
      loaded_entries = pickle.load(f)

  return loaded_index, loaded_entries

LoadDocData(file_path)
loaded_index, loaded_entries = LoadEntries()

# required utility functions.

# function to add entry to the document.
def append_to_docx(problem_text, solution_text):
    """Appends a new problem and solution to the 'problem.docx' file.

    Args:
        problem_text: The text of the problem.
        solution_text: The text of the solution.
    """
    try:
        doc = Document(file_path)
    except: # If the file doesn't exist, create a new one
        doc = Document()
        doc.add_paragraph("## Problem and Solution Entries")


    # Add the problem and solution
    doc.add_paragraph(f"Problem: {problem_text}")
    doc.add_paragraph(f"Solution: {solution_text}")

    # Save the document
    doc.save(file_path)
    #LoadDocData(file_path)
    #Lodaded_index, loaded_entries = LoadEntries()

# function to update an existing entry in the document.
def update_docx_entry(index, new_problem_text, new_solution_text):
    """Updates an existing problem and solution entry in the 'problem.docx' file.

    Args:
        index: The index of the entry to update (based on the loaded_entries list).
        new_problem_text: The new text for the problem.
        new_solution_text: The new text for the solution.
    """
    try:
        doc = Document(file_path)
        paragraphs = doc.paragraphs

        # Find the paragraphs corresponding to the entry at the given index.
        # Each entry consists of a "Problem:" paragraph and a "Solution:" paragraph.
        # The index in loaded_entries corresponds to the problem paragraph.
        # So, the problem paragraph is at index * 2, and the solution is at index * 2 + 1,
        # considering the initial "## Problem and Solution Entries" paragraph.
        problem_paragraph_index = index * 2 + 1
        solution_paragraph_index = index * 2 + 2

        if solution_paragraph_index < len(paragraphs):
            # Update the text of the problem and solution paragraphs
            paragraphs[problem_paragraph_index].text = f"Problem: {new_problem_text}"
            paragraphs[solution_paragraph_index].text = f"Solution: {new_solution_text}"
            doc.save(file_path)
            print(f"Entry at index {index} updated in Problem.docx")
            #LoadDocData(file_path)
            #Lodaded_index, loaded_entries = LoadEntries()
        else:
            print(f"Error: Index {index} out of range for updating.")

    except Exception as e:
        print(f"Error updating document: {e}")


# function to convert text to embeddings
def generate_embedding(text):
  """Generates an embedding for the input text using the loaded model.

  Args:
    text: The input text string.

  Returns:
    A numpy array representing the embedding of the text.
  """
  # Encode the text. model.encode expects a list.
  embedding = model.encode([text])
  # Return the first (and only) row of the embedding array
  return embedding[0]

# Semantic search function
def perform_semantic_search(embedding, k):
  """Performs a semantic search against the loaded FAISS index.

  Args:
    embedding: The embedding of the query text (numpy array).
    k: The number of nearest neighbors to retrieve.

  Returns:
    A tuple containing:
      - distances: A numpy array of distances to the nearest neighbors.
      - indices: A numpy array of indices of the nearest neighbors in the loaded_entries list.
  """
  # Reshape the embedding to match the expected input shape of index.search (1, dimension)
  embedding = embedding.reshape(1, -1)
  distances, indices = loaded_index.search(embedding, k)
  return distances, indices

# Function to call the LLM for comparison
import google.generativeai as genai
from google.colab import userdata

def compare_with_llm(new_entry, similar_entries):
    """
    Compares the new entry with similar entries using an LLM.

    Args:
        new_entry: The text of the new problem and solution.
        similar_entries: A list of text strings of similar entries from the document.

    Returns:
        A string containing the LLM's assessment.
    """
    # Configure the Gemini API
    GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')
    genai.configure(api_key=GOOGLE_API_KEY)

    # Initialize the Generative Model
    # Using gemini-1.5-flash-latest as gemini-flash-2 is not a valid model name
    # You can change this to the specific model you want to use if it's available
    gemini_model = genai.GenerativeModel('gemini-2.0-flash') #('gemini-1.5-flash-latest')

    # Create the prompt for the LLM
    #prompt = f"""Compare the following new entry with the existing similar entries.
    #Determine which entry provides the most accurate and informative solution to the problem.
    #Provide a brief explanation for your choice.

    prompt = f"""Compare the following new entry with the existing similar entries.
    Determine which has more information in the solution.
    if new entry has more information then return response as True else False.


    New Entry:
    {new_entry}

    existing similar Entries:
    {'- '.join(similar_entries)}

    Which entry is better and why?
    """

    # Call the LLM
    try:
        response = gemini_model.generate_content(prompt)
        return response.text.strip() # Strip whitespace from the response
    except Exception as e:
        return f"Error calling LLM: {e}"


def process_problem_solution(problem, solution):
    """
    Processes the input problem and solution, performs semantic search,
    and updates the document based on similarity and LLM comparison.

    Args:
        problem: The input problem string from the UI.
        solution: The input solution string from the UI.

    Returns:
        A tuple containing:
            - similarity_score_str: The calculated similarity score as a formatted string.
            - action_taken: A string describing the action taken (added, ignored, or compared with LLM).
            - comparison_result: A string containing the LLM comparison result (if performed).
    """
    # 2. Combine the problem and solution into a single string
    new_entry = f"Problem: {problem}\nSolution: {solution}"

    # 3. Use the generate_embedding function to get the embedding
    new_entry_embedding = generate_embedding(new_entry)

    # 4. Use the perform_semantic_search function to find the most similar existing entry
    # We need the top 1 result (k=1)
    k = 3
    distances, indices = perform_semantic_search(new_entry_embedding, k)

    # Extract the text of the similar entries
    similar_entries = [loaded_entries[i] for i in indices[0]]
    # Get the index of the most similar entry
    most_similar_index = indices[0][0]


    # 5. Calculate the similarity score from the returned distance for the top result.
    # Assuming L2 normalized embeddings, cosine similarity = 1 - ||a - b||^2 / 2
    # distances[0][0] is the squared Euclidean distance for the top result
    top_distance_squared = distances[0][0]
    similarity_score = 1 - (top_distance_squared / 2)

    # 6. Define the similarity_threshold
    similarity_threshold = 0.70

    comparison_result = "" # Initialize comparison result

    # 7. & 8. Compare the calculated similarity score with the similarity_threshold
    if similarity_score < similarity_threshold:
        # If similarity is below the threshold, add the new entry
        append_to_docx(problem, solution)
        action_taken = "Entry added to the knowledge base."
    else:
        # If similarity is at or above the threshold, a similar entry exists
        action_taken = "Similar entry found. Comparing with LLM."
        # Perform LLM comparison
        comparison_result = compare_with_llm(new_entry, similar_entries)

        # If comparison_result contains 'True', replace the existing similar content with new_entry
        if "True" in comparison_result:
             update_docx_entry(most_similar_index, problem, solution)
             action_taken += " Existing entry updated with new entry based on LLM comparison."
        else:
             action_taken += " Existing entry is better or equally good based on LLM comparison. New entry not added."


    # Format the similarity score for display
    similarity_score_str = f"{similarity_score:.4f}"


    # 9. Return the calculated similarity_score, the action_taken message, and the LLM comparison result
    return similarity_score_str, action_taken, comparison_result

import gradio as gr
from IPython.display import display

# Define the Gradio interface
interface = gr.Interface(
    fn=process_problem_solution,  # Your processing function
    inputs=[
        gr.Textbox(lines=5, label="Problem"),
        gr.Textbox(lines=5, label="Solution")
    ],
    outputs=[
        gr.Textbox(label="Similarity Score"),
        gr.Textbox(label="Action taken"),
        gr.Textbox(label="LLM Comparison Result")
    ],
    title="Problem and Solution Processor",
    description="Enter a problem and its solution to get processed results."
)

# Launch the interface
interface.launch(debug=True)

prb ='Email Not Sending from Outlook'
sln='Check SMTP server settings. Make sure the internet connection is stable. Clear the Outbox and restart Outlook. Re-enter password if account was recently updated. Repair Outlook profile via Control Panel > Mail.'
r1,r2,r3 = process_problem_solution(prb,sln)

print(r1)
print(r2)
print(r3)